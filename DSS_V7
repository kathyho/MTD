%% LyX 2.2.1 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[english]{article}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{geometry}
\geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
\usepackage{array}
\usepackage{float}
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{setspace}
\usepackage[numbers]{natbib}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}

\@ifundefined{date}{}{\date{}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\usepackage{babel}










\usepackage{babel}










\usepackage{babel}










\usepackage{babel}










\usepackage{babel}














\usepackage{babel}













\usepackage{babel}











\usepackage{babel}











\usepackage{babel}









\usepackage{babel}








\usepackage{babel}







\usepackage{babel}






\usepackage{babel}






\usepackage{babel}





\usepackage{babel}

\makeatother

\usepackage{babel}
\begin{document}

\title{The Time-Varying Nature of Social Media Sentiments in Modeling Stock
Returns}

\maketitle
\begin{doublespace}
\noindent Chi-San Ho\textsuperscript{a}, Paul Damien\textsuperscript{a,{*}},
Bin Gu\textsuperscript{b}, Prabhudev Konana\textsuperscript{a}

\noindent \textsuperscript{a}{\small{}McCombs School of Business,
University of Texas at Austin, 2100 Speedway Stop B6500, Austin, TX
78712, USA}{\small \par}

\noindent \textsuperscript{b}{\small{}W. P. Carey School of Business,
Arizona State University, Main Campus PO BOX 874606, Tempe, AZ 85287,
USA}{\small \par}
\end{doublespace}
\begin{abstract}
\begin{doublespace}
The broad aim of this paper is to answer the following related queries:
is the relationship between social media sentiments and stock returns
time-varying? To provide a satisfactory response, a novel methodology\textemdash a
symbiosis of Bayesian Dynamic Linear Models and Seemingly Unrelated
Regressions \textemdash is introduced. Two sets of Dow Jones Industrial
Average stock data and corresponding social media data from Yahoo!
Finance stock message boards are used in a comprehensive empirical
study. Some key findings are: (a) Affirmative response to the above
question; (b) Models with only social media sentiments and market
returns perform at least as well as models that include Fama-French
and Momentum factors; (c) There are significant correlations between
stocks, ranging from $-0.8$ to $0.6$ in both data sets. 
\end{doublespace}
\end{abstract}
\begin{doublespace}
Keywords: Bayesian Inference; Seemingly Unrelated Regressions; Social
Media Sentiments; Dynamic Linear Models; Markov Chain Monte Carlo 
\end{doublespace}

\vfill{}

\begin{onehalfspace}
\noindent \textbf{\textsuperscript{\textbf{{*}}}Corresponding Author:}

\noindent Paul Damien, B.M. (Mack) Rankin, Jr., Professor of Business
Administration

\noindent McCombs School of Business, University of Texas at Austin

\noindent {\small{}2100 Speedway Stop B6500}{\small \par}

\noindent {\small{}Austin, TX 78712-1277, USA}{\small \par}

\noindent Email: Paul.Damien@mccombs.utexas.edu\pagebreak{}
\end{onehalfspace}

\section{Introduction}

\begin{doublespace}
To better motivate this paper's contributions to the literature on
social media sentiments vis-a-vis their relationship to stock returns,
the introduction comprises two subsections wherein the first one offers
a comparative literature review, followed by an overview of this study. 
\end{doublespace}

\subsection{Motivation and Related Literature}

\begin{doublespace}
Opinions about stocks, products, businesses etc., on social media
sites such as social networks, virtual communities, and microblogging
services (e.g., Twitter) are ubiquitous. Numerous methodologies have
been proposed for mining opinions and emotions usually referred to
as social media sentiments. These sentiments have applications in
a variety of market services and investment settings; see, as examples,
\citep{mayzlin2003}, \citep{lugmayr2013}, \citep{luo2013social},
and \citep{tirunillai2012}. Importantly, social media facilitate
interactions among members who find relevant information and make
decisions (\citep{hagel1997}, \citep{rheingold2000}). Several commercial
products (e.g., SAS Social Media Analytics, Radian6, Socialmention)
incorporate tools to extract sentiments.

The ability to use social media sentiments for stock prediction has
attracted significant interest in academia and industry. As one example,
TDAmeritrade, an online stock broker, allows investors to post and
view sentiments of stocks and trade directly from this interface.
In this regard, the growing consensus was best captured by PredictWallStreet
on their website: 
\end{doublespace}
\begin{quote}
\begin{doublespace}
\textit{``The idea is simple. You share your opinion on whether you
think a stock or index will go up or down. PredictWallStreet combines
all the predictions it receives and provides information about the
community sentiment, accuracy of the community predictions as well
as forecasts for individual stocks, ETFs and indices. Since the stock
market moves based on the collective thinking of thousands of individuals,
the more people who make predictions on PredictWallStreet, the more
potentially useful the information becomes.''} 
\end{doublespace}
\end{quote}
\begin{doublespace}
This ``wisdom of the crowd'' provides market sentiments that can
be a proxy for the market mood. For instance, one of the largest social
media sites for stock related activity is Yahoo! Finance. In January
2014, ComScore Media Metrix reports that Yahoo! Finance received 39.6
million unique visitors while AOL's Money and Finance had 19.8 Million
visitors. Some stocks attract over 1000 messages per day on Yahoo!
Finance alone; see, \citep{Gu2007} and \citep{lugmayr2013single}.

There is substantial literature on the theoretical pros and cons of
social media sentiments and their relationship to modeling stock returns
and other metrics; as examples \citep{Antweiler2004,Bagnoli1999,bussegreen2002,dewally2003internet,li2014media,luo2013social,OhSheng2011,Tetlock2008,tetlock2007giving,Tumarkin2001,XuZhang2013}.
Recently, Sul et al. \citep{sul2016trading} study the predictability
of returns, based on sentiments expressed on Twitter. Using a multiple
linear regression model, they conclude that ``sentiment in tweets
about a specific firm from users with less than 171 followers...had
a significant impact on the stock's returns on the next trading day,
the next 10 days, and the next 20 days.'' Similarly, He et al. \citep{he2016social}
find that negative sentiments on Tweets could predict a firm's future
stock prices.

Another theoretical argument to study social media sentiments is often
described as follows: First, given the magnitude of investor attention
in these forums, social media sentiments from these forums capture
retail investors' sentiments on individual stocks which are known
to influence short-term stock performance (\citep{Barberis1998},
\citep{Delong1990}). Second, users on social media may have access
to insider information. Postings by insiders could reveal information
beyond what is publicly disclosed which influence future stock performance
(\citep{Bagnoli1999}, \citep{felton2002warnings}).

Thus, social media may reveal private information or market imperfections
that can be exploited for prediction of stock prices. The efficient
market hypothesis (EMH) argues that prices fully reflect all known
information, and that it is difficult to seek excess returns; see
\citep{malkiel2003efficient}. Hirshleifer \citep{hirshleifer2001investor}
provides an overview of psychological and behavioral arguments for
mis-pricing; see, also, \citep{kahneman1996reality} and \citep{thaler1985mental}.
Bounded rationality also suggests that individuals may fail to account
for repeated information and are subjected to greater bias (\citep{DeMarzo2003}).
However, discussions in social media may reflect investors' perceptions,
emotions, and heuristics. These sentiments may lead stock prices rather
than lag; if so, there are opportunities for at least short-term predictions
of stock returns.

Three aspects of social media have been closely studied: sentiments,
activity, and agreement. Sentiments capture bullishness or bearishness
of online postings. Activity measures the overall level of interests
in discussing a stock. Finally, agreement assesses convergence of
opinion among posts. Sentiments such as bullish, bearish, neutral
and agreement are often difficult to extract from messages because
of the volume and noise (\citep{Antweiler2004}, \citep{DasChen2007}).
Antweiler et al. \citep{Antweiler2004} found that the effect of message
board sentiments on stock returns was negative and statistically insignificant.
However, they show that activity (i.e., number of messages) and agreement
have significant predictability of stock volatility. 
\end{doublespace}

\subsection{Aims of this Research}

\begin{doublespace}
Our main focus is to examine a possible dynamic relationship between
social media sentiments and future stock returns. This is worthy of
study, since models of behavioral finance suggest that investor sentiments
could both underreact and overreact to underlying fundamentals; indeed,
it is this uncertainty that creates risks for arbitrageurs (\citep{Barberis1998},
\citep{Delong1990}). This gap between the empirical literature and
analytic models highlights the need to develop a method that allows
for a dynamic relationship between sentiments and future stock returns.
Here we tackle this issue via a combination of Bayesian Dynamic Linear
Models (DLMs) and Seemingly Unrelated Regressions (SURs); see, \citep{WestHarrison1997}
and \citep{Zellner1971}.

Unlike traditional regression models, our first methodological innovation,
via DLMs, allows sentiment regression coefficients to vary over time.
This enables us to capture both over-reaction and under-reaction by
investors. DLMs differ from traditional random coefficients models;
the latter allows regression parameters to be stochastic but not time-varying.
The second methodological contribution is the introduction of the
SUR approach within a DLM framework. The traditional linear regression
model and DLM assumes no cross-correlation between stock returns.
The SUR approach allows us to investigate multiple stocks as systems
of equations by explicitly modeling the cross-correlations between
returns, leading to statistically better estimates of the variances
of regression parameters. Thus, the DLM and SUR approaches serve different
and useful purposes. By exploiting the merits of both, we model stock
returns data as a dynamic function of social media sentiments.

At the outset, it is worth mentioning other models different than
our approach, and which have been used in the stock returns literature.
ARIMA models, such as GARCH and EGARCH, are primarily used to address
volatility, hence they are broadly classified as stochastic volatility
models. We do not model volatility. Rather, our focus is on understanding
the \emph{time-varying} behavior of social media regression parameters
and their impact on prediction. If the aim were to model stochastic
volatility, then GARCH or its variants would be viable choices.

Our SUR-DLM framework is quite different than the approach taken in,
for example, \citep{jostova2005bayesian}. In their model, ``beta''
refers to a firm's beta in a CAPM model. The authors then model that
beta as a stochastic process, resulting in a Bayesian formulation
via MCMC. This is very different than the research agenda for our
paper.

At times, data mining has been used to formulate new regressors (labeled
``mood trends'') before executing a standard multiple linear regression
to assess if these regressors are statistically significant (\citep{bollen2011twitter}).
We do not mine new regressors.

Finally, methodologically, many of the above references (such as \citep{bollen2011twitter}
and \citep{sul2016trading} ) use multiple linear regression which
is a (static) special case of the SUR model used in our paper. Importantly,
our focus is to use social media sentiments gathered from message
boards on Yahoo! Finance, and study their relevance in predicting
stock returns when such sentiments are treated as \emph{time-varying}.
Note that even though our focus is not on Twitter-based sentiments,
the mathematical approach taken here would readily apply to such data,
and related ones, as well.

Saving the details for later, here we briefly highlight some of the
key findings from this study. First, the impact of social media sentiments
on future stock returns vary over time. Second, there is considerable
correlation between stocks. Third, the time-varying social media sentiments
coefficients are more stable in 2011 when compared to 2009; the latter
was a period of high turbulence due to recession. Fourth, adding Fama-French
or Momentum factors (\citep{carhart1997}) underperforms a model with
just social media sentiments and market returns; that is, the prediction
errors are significantly larger compared to a model with just social
media sentiments and market returns.

Section 2 details the methodology and Section 3 describes the data.
Section 4 provides a comprehensive empirical study, followed by conclusions
in Section 5. 
\end{doublespace}

\section{Methodology}

\begin{doublespace}
The intuition underlying a DLM is simple yet powerful. At any time
$t$, the observed data $y_{t}$ is perturbed by noise (or error),
$u_{t}$. The expected value of $y_{t}$ is modeled via the regression
term $X\beta$. The thrust of the DLM is to allow the $\beta$ vector
to evolve over time, which in turn would affect the expected value
to evolve as well. The OLS estimation is a special case when $\beta$
is fixed. Likewise, the DLM is more general than the traditional random
coefficients model where the coefficient is random with a fixed mean.
The evolutionary dynamics of $\beta$, typically, is modeled as an
autoregressive process with additional noise (or error) over time,
say $v_{t}$. The error $u_{t}$ is called the observation error,
while $v_{t}$ is called the system error, leading to two inter-related
equations, namely the Observation and System (or State) equations.
Following West and Harrison \citep{WestHarrison1997}, the observation
equation is given by

\begin{equation}
y_{t}=X_{t}'\beta_{t}+u_{t}\hspace{0.3cm}u_{t}\sim N_{p}(0,\,U_{t}),\;t=1,...,n,
\end{equation}
and the system regression equation

\begin{equation}
\beta_{t}=G_{t}\beta_{t-1}+v_{t}\hspace{0.3cm}v_{t}\sim N_{q}(0,\,V_{t}).
\end{equation}

Note that one obtains the standard multiple linear regression model
if the systems equation is ignored. We assume that the $u_{t}$ and
$v_{t}$ are mutually independent; the matrix $G$ is assumed known.
Also, the system equation above is an autoregression of order one.
In general, one could include higher order terms. For our application,
we found a first order systems equation model was sufficient since
adding more terms may lead to over-fitting; \citep{WestHarrison1997}
also caution the use of these models in the direction of parsimony.

For both estimation and prediction, the first goal is to find the
posterior distributions of $\beta_{t}$, $t=1,\cdots,n$. With prior
distributions for the vector of these slopes, $U_{t}$, $V_{t}$ (or
the ratio $V_{t}/U_{t}$), it is possible to obtain the posterior
distributions of all the random variables in the model. This would
correspond to the Estimation Phase of the DLM. One could then derive
the predictive distribution of stock returns in the Prediction Phase.
Details are provided in the Appendix. 
\end{doublespace}

\subsection{Seemingly Unrelated Regression (SUR) Model }

\begin{doublespace}
In a traditional linear regression model for stock returns, in matrix
notation, one would have, 
\begin{equation}
y=X\beta+u,
\end{equation}
where $y$ is the vector of stock returns, $X$ is the matrix of regressors
(social media sentiments, market returns, Fama-French, Momentum Factors,
etc.), $\beta$ is a vector of unknown but fixed parameters and $u$
is random error, which is typically assumed to be normally distributed
with zero mean and unknown variance-covariance matrix, $\Sigma$.
The parameter vector $\beta$ is estimated via OLS. The above model
assumes no correlations between various stock returns.

In contrast, the SUR approach (\citep{Ando2010}, \citep{Zellner1971})
explicitly models the correlations between stock returns. For the
moment, assume the regression parameter vector $\beta$ to be fixed
in \emph{time}, but unknown; later, we will make it time-varying,
random and unknown. Let $j$ denote the return on the $j$th stock
and $M$ denote the total number of stocks. Let $n$ be the total
number of observations (in days) for each stock. We have:

\begin{equation}
\begin{array}{c}
y_{j}=X_{j}\beta_{j}+u_{j},j=1,\ldots,M,\\
\mathrm{\;with\;}E[u_{i}u_{j}']=\begin{cases}
\omega_{ij}I, & (i\neq j)\\
\omega_{i}^{2}I, & (i=j);
\end{cases}
\end{array}
\end{equation}

$y_{j}$ and $u_{j}$ are $n\times1$ vectors, $X_{j}$ is an $n\times p_{j}$
matrix of rank $p_{j}$ of observations, and $\beta_{j}$ is a $p_{j}$-dimensional
coefficient vector. The domain of parameter values are given as follows:
$\beta_{jr}\in\mathbb{R}$, ($r=1,\ldots,p_{j},j=1,\ldots,M$), $\omega_{ij}\in\mathbb{R}$,
($i,j=1,\ldots M,i\neq j$) and $\omega_{j}\in\mathbb{R}_{>0}$, ($j=1,\ldots M)$.
This system of equations extends the traditional multiple linear regression
model to include two critical and practically useful features: 
\end{doublespace}
\begin{itemize}
\begin{doublespace}
\item The error terms in each equation are allowed to be correlated. Since
each equation represents a particular stock's returns, this assumption
implies that the model accounts for correlations between these stock
returns. Clearly this is a useful feature to impose: businesses competing
in the same market would likely have negative correlations in their
returns, while those participating in the same ecosystem might have
positive correlations. 
\item Each equation in the system could have different independent variables
(or regressors) and variances. This is also a reasonable assumption,
for there is no \emph{a priori} reason to suppose that each of the
stocks in the Dow Jones Industrial Average (DJIA) require the same
set of regressors to explain and predict it. The same argument could
also apply to the volatilities in these stock returns. 
\end{doublespace}
\end{itemize}
\begin{doublespace}
It is convenient to express the SUR model using matrix notation: 
\begin{equation}
y=X\beta+u,
\end{equation}
$u\sim N(0,\Omega\otimes I),$ where $N(\mu,\Sigma)$ denotes the
normal distribution; $\otimes$ is the tensor product; $\Omega$ is
an $M\times M$ symmetric matrix with diagonal elements $\omega_{1}^{2},\ldots\omega_{M}^{2}$,
and the off-diagonal $ij$th elements are $\omega_{ij}$; $y'=(y'_{1},\ldots,y'_{M})$;
$X=$diag$\left(X_{1},\ldots X_{M}\right)$; $\beta'=(\beta'_{1},\ldots,\beta'_{M})$;
and $u'=(u'_{1},\ldots,u'_{M})$.

The normal likelihood function for the above model is given by: 
\begin{equation}
L(y\mid\beta,\Omega)=\frac{1}{(2\pi)^{nM/2}\mid\Omega\mid^{n/2}}\exp\left[-\frac{1}{2}\mathrm{tr}\left\{ R\Omega^{-1}\right\} \right],
\end{equation}
where ``tr'' denotes the trace of a matrix; $\mid\Omega\mid=\det(\Omega)$
is the determinant of $\Omega$; and the $ij$th element of the $M\times M$
matrix $R$ is $r_{ij}$ and $r_{ij}=(y_{i}-X_{i}\beta_{i})'(y_{j}-X_{j}\beta_{j})$.

It is possible to estimate the parameters of the SUR model using a
non-Bayesian approach. But later we imbed the SUR into a DLM framework
to allow the regression vector, $\beta$, to vary over time, thus
requiring a Bayesian approach to estimation and prediction (\citep{WestHarrison1997}).
Also, Zellner \citep{Zellner1971} offers compelling reasons why a
Bayesian approach to the SUR model is preferred over standard estimation
methods.

To complete the Bayesian specification, following Zellner \citep{Zellner1971},
consider Jeffrey's invariant prior for $(\beta,\,\Omega)$, where
$\pi(.)$ denotes a prior distribution:

\begin{equation}
\pi(\beta,\Omega)=\pi(\beta)\pi(\Omega)\propto\mid\Omega\mid^{-\frac{M+1}{2}},
\end{equation}
where the last term above is the square root of the determinant of
the Fisher information matrix. Jeffery's prior is invariant under
any one-to-one re-parametrization of the model and, as a result, is
frequently used in the literature. The theoretical notion of invariance
is somewhat involved. Intuitively, Jeffrey's prior is appealing when
used with scale parameters. That is, it does not matter, for instance,
if one characterizes the model, say using the variance or standard
deviation; the prior is valid under both of these \emph{scale parametrizations}.

The posterior joint density function, by Bayes' theorem, is given
by:

\begin{equation}
g(\beta,\Omega\mid Y,X)\propto\mid\Omega\mid^{-(n+M+1)/2}\exp\left[-\frac{1}{2}\mathrm{tr}\left\{ R\Omega^{-1}\right\} \right].
\end{equation}

From the above, given that one assumes prior distributions on $\beta$
and $\Omega$, these quantities are random and unknown. This is in
sharp contrast to standard linear regressions where they are fixed
and unknown. Also, $\beta$ is not time-varying in the above SUR model:
later, when we include the SUR into a DLM, the $\beta$ vector will
also become time-varying.

In regression, the two goals of any statistical inference procedure
are to explain the impact of the regressors on the dependent variable
and to predict future values of the dependent variable. For the above
model, it is relatively straightforward to construct a Markov chain
Monte Carlo (MCMC) method, namely a Gibbs Sampler to accomplish both
these goals; see, \citep{Ando2010} and \citep{Chib2013}. To implement
a Gibbs sampler, we first need to derive the conditional distributions
of the unknown, random parameters; these distributions need to be
known only up to proportionality. 
\end{doublespace}
\begin{itemize}
\begin{doublespace}
\item ESTIMATION PHASE: The posterior conditional distributions $g(\beta\mid\Omega,Y,X)$
and $g(\Omega\mid\beta,Y,X)$ are: 
\end{doublespace}
\end{itemize}
\begin{doublespace}
\begin{equation}
\begin{array}{c}
g(\beta\mid\Omega,Y,X)=N(\hat{\beta},\hat{\Omega}_{\beta}),\\
\mathrm{and\quad}g(\Omega\mid\beta,Y,X)=IW(R,n)
\end{array}
\end{equation}
where $IW(\cdot,\cdot)$ denotes the inverse Wishart distribution,
and 
\end{doublespace}
\begin{quote}
\begin{doublespace}
$\hat{\beta}=\left\{ X'(\Omega^{-1}\otimes I)X\right\} ^{-1}X'(\Omega^{-1}\otimes I)\cdot y$,

$\hat{\Omega}_{\beta}=(X'(\Omega^{-1}\otimes I)X)^{-1}$. 
\end{doublespace}
\end{quote}
\begin{doublespace}
Note that the estimation of $\hat{\beta}$ has the same form as the
classical method; see \citep{Zellner1971}. As a result of using Jeffery's
prior, the estimated regression coefficients will be very close to
those from the classical method. However, unlike the classical method,
in this Bayesian model one can obtain the complete predictive distribution
of the stock returns vector $y$, to which we now turn. 
\end{doublespace}
\begin{itemize}
\begin{doublespace}
\item PREDICTION PHASE: The predictive distribution for a future vector
of stock returns, $y$, given $x,$ $\beta$ and $\Omega$ is derived
as follows. With $y_{j}$ denoting the $j$th stock's return, let
$y_{j}$ be an $n\times1$ vector. At time, say $n+1$, what is the
distribution of $y_{j}^{n+1}$ given $\beta$, $\Omega$ and the $(n+1)$th
row in each of the regressor matrices $X_{j}$? To answer this, first
stack all the $y$ values we want to predict at time $n+1$; that
is, the $y_{j}^{n+1}$ are stacked and denoted as $Y_{n+1}$; likewise
the augmented $X$ matrix is diag$\left\{ X_{1}^{n+1},\ldots,\,X_{M}^{n+1}\right\} $.
To directly sample from $Y_{n+1}$ is difficult. However, we can achieve
this easily via the Gibbs sampler from the Estimation Phase (\citep{Percy1992}).
We have: 
\end{doublespace}
\end{itemize}
\begin{doublespace}
\begin{equation}
f(Y_{n+1}\mid X\,,\beta\,,\Omega)=N(X\beta,\,\Omega)
\end{equation}
\begin{equation}
\:\begin{array}{c}
f(\beta\mid\Omega,Y_{n+1},X)=N(\hat{\beta},\hat{\Omega}_{\beta})\\
\mathrm{and\:}f(\Omega\mid\beta,Y_{n+1},X)=IW(R,n+1).
\end{array}
\end{equation}

Let us recap the value of the Bayesian SUR model: it explicitly models
the cross-correlations between the $M$ stock returns via the system
of equations. Second, the regression parameter vector $\beta$ is
random; hence we are able to obtain its posterior distribution rather
than a point estimate. Hence, the regression coefficient on social
media sentiments could evolve each day due to market dynamics or \emph{system}
noise: this is in addition to the noise one observes in stock returns
data which is conventionally called \emph{observation} error. To allow
the regression coefficient vector $\beta$ in the Bayesian SUR model
to evolve over time, we will embed the SUR component into a DLM. Finally,
one can obtain the entire predictive distribution for $each$ stock
at $any$ future point in time. 
\end{doublespace}

\subsection{SUR model with Dynamic coefficients }

\begin{doublespace}
Since one of the main aims of the paper is to assess the impact of
social media sentiments on future stock returns, we use the DLM for
the regression parameters corresponding to social media sentiments;
that is, we allow its regression coefficients to be time-varying in
all the equations in the SUR model. The remaining regression parameters
are assumed to be non time-varying but still random. We have:

\begin{equation}
\begin{array}{c}
y_{j,t}=\alpha_{j}+X_{j,t}\beta_{j,t}+Z_{j,t}\gamma_{j}+u_{j,t}\\
\beta_{j,t}=\beta_{j,t-1}+v_{j,t}\\
\mathrm{for\;}j=1,\ldots,M,\qquad t=1,...,n,
\end{array}
\end{equation}

where $y_{j,t}$, $\alpha_{j}$, $X_{j,t}$, $\beta_{j,t}$,$u_{j,t}$,
$v_{j,t}$ are scalars and in particular, $X_{j,t}$ corresponds to
the time-varying regressors, namely social media sentiments. The $Z_{j,t}$
are $1\times p_{j}$ vectors and $\gamma_{j}$ are $p_{j}\times1$
vectors, corresponding to non time-varying (or static) regressors
and coefficients which may include Fama-French factors and market
returns. A listing of these static regressors for each model in our
study is provided in the next section.

Let $u_{t}=(u_{1,t},...,u_{M,t})^{T}$ and $v_{t}=(v_{1,t},...,v_{M,t})^{T}$,
then

\[
u_{t}\sim i.i.d.\,N_{M}(0,\Omega)\;\mathrm{and}\;v_{t}\sim i.i.d.\,N_{M}(0,\Sigma),
\]
where $\Sigma=A\Omega A$. $A$ is a diagonal matrix, $\{A\}_{jj}=((1-\delta_{j})/\delta_{j})^{\frac{1}{2}}$,
where $0<\delta_{j}<1$ specifies the signal to noise ratio.

What is the role of $\delta_{j}$? Note that when $\delta_{j}\rightarrow1$,
the contribution of the error or noise from the system equation to
the observation equation (via $\Omega$) declines. In practice, the
$\delta_{j}$s are assumed known, typically $0.9$ to $0.99$ (\citep{WestHarrison1997}).
On the other hand, it is also possible to allow $\delta_{j}$ to be
random. In the Appendix we develop the mathematics in its most general
form where we let the $\delta_{j}$s be random. The key point is the
$\delta_{j}$s specify the strength of the relationship between $\Omega$
and $\Sigma$, namely the covariances in the observation and system
equations, respectively. Thus, as the $\delta_{j}$s approach one,
the estimation of the regression parameters are less dependent on
the noise from the system equations. In our context, this would mean
that as the $\delta_{j}$s approach one, the time volatility in the
slopes of the social media sentiment coefficients are more impacted
by the observation error in the stock returns data than the dynamics
stemming from the system error.

Given $\delta_{j}$, the \emph{random}, unknown parameters in our
DLM-SUR model are collected together in the vector $\Theta=\{\alpha_{j},\,\beta_{j,1:n},\,\gamma_{j},\,\Omega\}$;
in this vector, the \emph{only} component that is \emph{time-varying}
is the collection of regression slopes, generically denoted as $\beta$.
The data are collected together in the vector $D_{n}=\{y_{j,1:n},\,X_{j,1:n},\,Z_{j,1:n}\}$,
where the first, second and third components correspond, respectively,
to the stock returns, the regressors whose coefficients vary in time,
and the regressors whose coefficients are fixed in time. Combining
Jeffery's prior for the SUR model parameters with the prior distribution
for the DLM parameters, the prior joint distribution for $\Theta$
is given by:

\begin{equation}
\pi(\Theta)\propto\pi(\Omega)\pi(\beta_{0})\propto\mid\Omega\mid^{-\frac{M+1}{2}}\cdot N_{M}(m_{0},\,C_{0}).
\end{equation}

In the above, all parameters with a subscript $0$ correspond to those
from the DLM component of the model. Since the posterior distribution
of $\Theta$ will not have a closed form solution, we would have to
use MCMC methods for the estimation and prediction phases of the analysis.
To this end, like before, a Gibbs sampler algorithm is derived. Saving
the details for the Appendix, to execute a Gibbs sampler for the combined
DLM-SUR system of equations, we need the following conditional distributions
to sample the various components in $\Theta$ and the predictive distribution
of $Y_{n+1}$. 
\end{doublespace}

\begin{equation}
f(\alpha_{1:M}|D_{n},\Theta/\{\alpha_{1:M}\})\sim N_{M}(\mu_{\alpha},\Sigma_{\alpha})
\end{equation}

\begin{equation}
f(\gamma|D_{n},\Theta/\{\gamma_{1:M}\})\sim N_{P}(\mu_{\gamma},\Sigma_{\gamma})
\end{equation}
\begin{equation}
f(\beta_{j,1:n}|D_{t},\Theta/\{\beta_{j,1:n}\})\sim FFBS
\end{equation}

\begin{equation}
f(\Omega|D_{n},\Theta/\{\Omega\})\sim IW(R,T),
\end{equation}
\begin{equation}
f(Y_{n+1}|D_{n+1},\Theta)\sim N_{M}(\mu_{p},\Sigma_{p}),
\end{equation}

\begin{doublespace}
\noindent where $FFBS$ stands for Filter Forward Backward Sampling
algorithm, $N$ denotes the normal distribution and $IW$ denotes
the inverse-Wishart distribution. In the above, the notation $f(\alpha_{1:M}|D,\Theta/\{\alpha_{1:M}\})$
means the posterior conditional distributions of $\alpha_{1:M}$ given
the data, $D$, and all the other parameters in the vector $\Theta$
\emph{excluding} the $\alpha_{1:M}$ parameters; likewise for all
the other conditional distributions shown above. Thus, the Gibbs sampler
will generate samples from the posterior distributions of all the
random parameters in the model. This is the estimation phase. The
equations for the prediction phase are detailed in the Appendix. Basically,
for the latter phase, one uses the samples from the estimation phase
to approximate the integrals corresponding to the predictive densities
of each stock return at each time point. 
\end{doublespace}

\section{Data Description}

\begin{doublespace}
The datasets consist of message posts collected from Yahoo! Finance
from January 2009 to June 2009 and from June 2011 to June 2012. Given
the large number of stock message boards and the amount of time it
takes to collect posts, for our analysis, we chose stocks from a well-known
market index, the Dow Jones Industrial Average (DJIA)\footnote{\begin{doublespace}
The 2009 data consists of 128 transactions days with 29 stocks from
the DJIA. The 29 stocks include Citigroup which was replaced by The
Travelers Companies (TRV) but do not include General Motors (GM) which
filed for bankruptcy and has since been replaced by Cisco Systems
(CSCO). The 2011 data consists of 252 transaction days with 30 stocks
from the DJIA at that time including Kraft (KFT) which was replaced
by United Health (UNH) in September 2012. 
\end{doublespace}
}, as a representative set of large-cap stocks. The choice of data
is similar to Antweiler and Frank (2004) who considered 45 stocks
drawn from two stock indices, namely DJIA and Dow Jones Internet Commerce
Index (XLK). The descriptive statistics for the data are in Tables
1 and 2.

The data on social media sentiment measures range from -2 to 2, where
-2 represents a strong sell signal, +2 represents a strong buy signal,
and 0 represents a hold signal. Note that these values do not represent
agreement, bearishness, and bullishness. The sentiment posts are self-declared
sentiments. Messages without self-declared sentiments were excluded.
If there were no self-declared messages for a stock on a given day,
we imputed it to represent a ``hold''. This may be debatable but
it is a reasonable assumption, especially in conjunction with the
large number of messages. Importantly, if one brings in the fact that
most investors are risk averse, then neutrality, in our context, could
be far more difficult to justify than ``hold''. Table 2 shows the
maximum messages for each of the stocks in the 2011 dataset. Due to
copious changes on the Yahoo! Finance website, we could not retrieve
similar data for 2009.

\begin{table}
\begin{centering}
\caption{Descriptive statistics for 2009 data set}
\par\end{centering}
\medskip{}

\begin{centering}
\begin{tabular}{lccccc}
 &  & \multicolumn{2}{c}{Daily Returns } & \multicolumn{2}{c}{Daily Sentiment }\tabularnewline
\hline 
Company  & Ticket  & Mean  & SD  & Mean  & SD\tabularnewline
\hline 
Alcoa  & AA  & 0.40\%  & 0.27\%  & 1.00  & 0.07\tabularnewline
American Express  & AXP  & 0.47\%  & 0.22\%  & -0.47  & 0.10\tabularnewline
Boeing  & BA  & 0.22\%  & 0.16\%  & 0.20  & 0.09\tabularnewline
Bank of America  & BAC  & 0.14\%  & 0.24\%  & 0.91  & 0.03\tabularnewline
Citigroup  & C  & 0.16\%  & 0.34\%  & 1.03  & 0.04\tabularnewline
Caterpillar  & CAT  & 0.47\%  & 0.22\%  & 0.16  & 0.09\tabularnewline
Chevron  & CVX  & 0.14\%  & 0.11\%  & 0.66  & 0.09\tabularnewline
DuPont  & DD  & 0.25\%  & 0.18\%  & 0.67  & 0.08\tabularnewline
Walt Disney  & DIS  & 0.28\%  & 0.15\%  & 0.69  & 0.10\tabularnewline
General Electric  & GE  & 0.24\%  & 0.20\%  & 0.61  & 0.05\tabularnewline
Home Depot  & HD  & 0.18\%  & 0.13\%  & 0.15  & 0.10\tabularnewline
Hewlett-Packard  & HPQ  & 0.24\%  & 0.11\%  & -0.13  & 0.06\tabularnewline
IBM  & IBM  & 0.19\%  & 0.10\%  & 0.30  & 0.08\tabularnewline
Intel  & INTC  & 0.19\%  & 0.14\%  & 0.99  & 0.05\tabularnewline
Johnson \& Johnson  & JNJ  & 0.11\%  & 0.07\%  & 0.91  & 0.08\tabularnewline
JP Morgan Chase  & JPM  & 0.18\%  & 0.19\%  & -1.43  & 0.04\tabularnewline
Kraft  & KFT  & 0.08\%  & 0.11\%  & 0.31  & 0.08\tabularnewline
Coca-Cola  & KO  & 0.15\%  & 0.08\%  & 0.59  & 0.08\tabularnewline
McDonald's  & MCD  & 0.08\%  & 0.09\%  & 0.82  & 0.09\tabularnewline
3M  & MMM  & 0.27\%  & 0.12\%  & 0.29  & 0.07\tabularnewline
Merck  & MRK  & 0.24\%  & 0.14\%  & 0.47  & 0.11\tabularnewline
Microsoft  & MSFT  & 0.21\%  & 0.14\%  & 0.79  & 0.06\tabularnewline
Pfizer  & PFE  & 0.18\%  & 0.12\%  & 1.48  & 0.05\tabularnewline
Procter \& Gamble  & PG  & 0.15\%  & 0.10\%  & 0.90  & 0.08\tabularnewline
AT\&T  & T  & 0.13\%  & 0.10\%  & 0.77  & 0.07\tabularnewline
United Technologies  & UTX  & 0.25\%  & 0.12\%  & 0.26  & 0.06\tabularnewline
Verizon Communications  & VZ  & 0.09\%  & 0.10\%  & 0.79  & 0.09\tabularnewline
Wal-Mart  & WMT  & 0.09\%  & 0.07\%  & 1.22  & 0.05\tabularnewline
Exxon Mobil  & XOM  & 0.00\%  & 0.11\%  & 0.57  & 0.08\tabularnewline
Market return (S\&P 500)  & \textasciicircum{}GSPC  & 0.17\%  & 0.10\%  &  & \tabularnewline
\hline 
\end{tabular}
\par\end{centering}
\medskip{}

SD : standard deviation 
\end{table}

\begin{table}
\begin{centering}
\caption{Descriptive statistics for 2011 data set}
\par\end{centering}
\medskip{}

\begin{centering}
\begin{tabular}{ccccccc}
 &  & \multicolumn{2}{c}{Daily Return } & \multicolumn{2}{c}{Daily Sentiment } & \tabularnewline
\hline 
\multirow{2}{*}{Company } & \multirow{2}{*}{Ticket } & \multirow{2}{*}{Mean } & \multirow{2}{*}{SD } & \multirow{2}{*}{Mean } & \multirow{2}{*}{SD } & Maximum\tabularnewline
 &  &  &  &  &  &  \# of Messages\tabularnewline
\hline 
Alcoa  & AA  & -0.20\%  & 0.17\%  & 0.69  & 0.05  & 89\tabularnewline
American Express  & AXP  & 0.06\%  & 0.12\%  & 0.00  & 0.07  & 4\tabularnewline
Boeing  & BA  & -0.01\%  & 0.12\%  & 0.49  & 0.07  & 10\tabularnewline
Bank of America  & BAC  & -0.09\%  & 0.25\%  & 0.60  & 0.03  & 374\tabularnewline
Caterpillar  & CAT  & -0.03\%  & 0.15\%  & 1.02  & 0.04  & 48\tabularnewline
Cisco  & CSCO  & 0.03\%  & 0.13\%  & 1.01  & 0.04  & 116\tabularnewline
Chevron  & CVX  & 0.01\%  & 0.11\%  & 1.01  & 0.05  & 12\tabularnewline
DuPont  & DD  & 0.01\%  & 0.12\%  & 0.16  & 0.05  & 4\tabularnewline
Walt Disney  & DIS  & 0.08\%  & 0.12\%  & 0.49  & 0.06  & 18\tabularnewline
General Electric  & GE  & 0.03\%  & 0.12\%  & 0.15  & 0.04  & 46\tabularnewline
Home Depot  & HD  & 0.17\%  & 0.10\%  & 0.14  & 0.07  & 8\tabularnewline
Hewlett-Packard  & HPQ  & -0.16\%  & 0.16\%  & 0.41  & 0.05  & 97\tabularnewline
IBM  & IBM  & 0.07\%  & 0.09\%  & 0.67  & 0.07  & 54\tabularnewline
Intel  & INTC  & 0.09\%  & 0.10\%  & 1.59  & 0.02  & 64\tabularnewline
Johnson \& Johnson  & JNJ  & 0.00\%  & 0.06\%  & 0.58  & 0.06  & 10\tabularnewline
JP Morgan Chase  & JPM  & -0.04\%  & 0.17\%  & -0.49  & 0.06  & 216\tabularnewline
Kraft  & KFT  & 0.06\%  & 0.06\%  & 0.42  & 0.05  & 6\tabularnewline
Coca-Cola  & KO  & 0.06\%  & 0.07\%  & 0.49  & 0.05  & 7\tabularnewline
McDonald's  & MCD  & 0.05\%  & 0.07\%  & 0.73  & 0.06  & 20\tabularnewline
3M  & MMM  & -0.01\%  & 0.11\%  & 0.29  & 0.04  & 4\tabularnewline
Merck  & MRK  & 0.05\%  & 0.08\%  & 0.24  & 0.06  & 6\tabularnewline
Microsoft  & MSFT  & 0.09\%  & 0.10\%  & 0.90  & 0.03  & 36\tabularnewline
Pfizer  & PE  & 0.04\%  & 0.09\%  & 0.86  & 0.06  & 15\tabularnewline
Procter \& Gamble  & PG  & -0.01\%  & 0.06\%  & 0.60  & 0.06  & 11\tabularnewline
AT\&T  & T  & 0.07\%  & 0.07\%  & 0.38  & 0.05  & 42\tabularnewline
Travelers Companies  & TRV  & 0.03\%  & 0.11\%  & 0.15  & 0.04  & 2\tabularnewline
United Technologies  & UTX  & -0.04\%  & 0.11\%  & 0.50  & 0.06  & 6\tabularnewline
Verizon Communications  & VZ  & 0.09\%  & 0.07\%  & 0.71  & 0.06  & 34\tabularnewline
Wal-Mart  & WMT  & 0.10\%  & 0.07\%  & 0.04  & 0.04  & 38\tabularnewline
Exxon Mobil  & XOM  & 0.76\%  & 0.09\%  & 0.91  & 0.05  & 28\tabularnewline
Market return (S\&P 500)  & \textasciicircum{}GSPC  & 0.00\%  & 0.09\%  &  &  & \tabularnewline
\hline 
\end{tabular}
\par\end{centering}
\medskip{}

\raggedright{}SD : standard deviation 
\end{table}

\end{doublespace}

\section{Analysis}

\begin{doublespace}
The following abbreviations are used throughout the discussion of
the analysis. SR: stock returns; MR: market returns; CS: weighted
social media sentiment; SMB: Fama-French small market capitalization
minus big market capitalization factor; HML: Fama-French high book-to-market
ratio minus low book-to-market ratio factor; UMD: momentum factor.
All the independent variables are lagged one time period. This is
because we are interested in stock returns at time $t$ given the
independent regressor values at time $t-1$. That is, we are interested
in forecasting one-step ahead since investment decisions (such as
buy, hold or sell) are made \emph{ex ante}. However, in CAPM, market
returns and other factors are usually treated contemporaneously. 
\end{doublespace}

\subsection{Modeling and Parameter Estimation}

\begin{doublespace}
For each data set, we construct three models to compare the predictability
of CS versus the full-factor Fama-French/momentum models. Model 1
includes the dynamic CS regressor and the static Market Return factor;
the second is the SUR model with the static Fama-French and momentum
factors; and the third is the DLM-SUR model with CS, Fama-French and
momentum factors. Table 3 provides the regressors in the three models.
These three models allow us to isolate the effect of CS from the other
factors on stock returns.

In canonical notation, with $SR_{j,t}$ denoting the $j$th stock's
returns at time $t$, all three models can be written as following.

\begin{equation}
\begin{array}{c}
SR_{j,t}=\alpha_{j}+CS_{j,t}\beta_{j,t}+Z_{j,t}\gamma_{j}+u_{j,t},\\
CS_{j,t}=CS_{j,t-1}+v_{j,t},\\
j=1,\ldots,M,\:t=1,...,n,
\end{array}
\end{equation}

\[
u_{j,t}\sim i.i.d.\,N_{M}(0,\Omega)\;v_{j,t}\sim i.i.d.\,N_{M}(0,\Sigma),
\]
where $\Sigma=A\Omega A$; the $Z_{j,t}$ contain the static regressors.
Recall from the methodology section, $A$ is a diagonal matrix such
that$\{A\}_{jj}=((1-\delta_{j})/\delta_{j})^{\frac{1}{2}}$, where
$\delta_{j}$ specifies the signal to noise ratio for each stock.
We tried different fixed values for $\delta_{j}$ and settled for
$0.99$ for all our models, since the results were similar even if
we reduced them to, say $0.9$. In other words, we allowed the signal
in the observation equation to capture more of the uncertainty in
the parameter estimates, as well as the predictions.

\begin{table}
\begin{centering}
\caption{The list of regressors in the three models }
\par\end{centering}
\centering{}%
\begin{tabular}{ccc}
Model  & Dynamic Regressors ($\beta$)  & Static Regressors ($Z$)\tabularnewline
\hline 
1  & CS  & MR\tabularnewline
2  &  & MR, SMB, HML, UMD\tabularnewline
3  & CS  & MR, SMB, HML, UMD\tabularnewline
\hline 
\end{tabular}
\end{table}

\end{doublespace}

\subsection{Estimation Phase}

\begin{doublespace}
The estimation phase serves two purposes. First, to validate the claim
that the slopes of the regression parameters for the CS coefficients
are time-varying; this validation is accomplished using the DLM approach.
Second, to demonstrate, via the posterior distributions of the variance-covariance
matrix of the SUR model, the importance of considering cross-correlations
between stocks in the datasets. In practical terms, a positive CS
on a given stock not only affects the focal stock but also other stocks
that are positively correlated with the focal stock. Hence modeling
these correlations is important in both the estimation and prediction
phases. 
\end{doublespace}

\subsubsection{The estimated regression coefficients for the time-varying CS variable}

\begin{doublespace}
To better focus the discussion, we pick six stocks to report. These
stocks are American Express (AXP), Bank of America (BAC), Walt Disney
(DIS), General Electrics (GE), JP Morgan Chase (JPM) and Microsoft
(MSFT). In the interests of space, we do not report the results of
all the other stocks. They are available upon request.

\emph{Validating the time-varying aspect of the CS regression slopes:}
the CS coefficients from Model 1 for these six stocks are shown in
Figures 1 and 2. The solid and dotted curves are the CS time-varying
posterior means and their 90\% uncertainty bands, respectively, obtained
by implementing the algorithm detailed in the Appendix. Note that
the AXP CS coefficients in both data sets change considerably, as
does JPM's. In contrast, the time-varying CS coefficients for MSFT
and DIS are fairly stable over time in both data sets. For all four
stocks, the estimated coefficients vary over time, taking on both
positive and negative values at different time periods. Similar inferences
were noted for the remaining stocks in the data sets. The results
suggest that it would be inappropriate to assume that the CS regression
coefficients are fixed in time for all these stocks when the analysis
clearly points to significant time-varying evolution in some stocks.
Put differently, assuming these slopes and intercepts to be fixed
would mean there is just \emph{one} unique line for each stock, implying
(erroneously) a fixed rate of change in that stock's returns for a
unit change in CS across \emph{all} time periods.

To elaborate on the last point above, consider Table 4. For the six
stocks, for each of the two data sets, 2009 and 2011, the first, second,
and third rows correspond, respectively, to the posterior means, the
fifth, and 95th percentiles. For the sake of illustration, these numeric
values correspond to the \emph{last} point shown in Figures 1 and
2. The last row in the table for each of the two datasets is the value
of the slope coefficients for the six stocks obtained from running
six static multiple linear regression models, one for each stock,
with CS and MR. The estimated slope coefficients are markedly different
from the DLM-SUM approach since the forecast, both in-sample and out-of-sample,
use the \emph{same} value for the coefficient. In reality, Figures
1 and 2 demonstrate how these six coefficients \emph{adapt} to both
the observation and system noise, \emph{evolving} from one day to
the next, starting with day one. Also, Table 4 provides rich summaries
like the 5th and 95th percentiles of the posterior distributions of
the CS coefficients, allowing researchers and practitioners to quantify
the uncertainty. It is possible to construct confidence intervals
for the static regression coefficients. However, like the mean estimates,
these intervals will be the \emph{same} for each day, whereas the
Bayesian intervals will change \emph{each} day, based on evolving
observation and system noises.

The upshot of the above discussion is this: \emph{the impact of social
media sentiments on future stock returns is time-varying.} This was
one of the primary hypotheses that this paper sought to examine. 
\end{doublespace}

\begin{figure}
\begin{centering}
\caption{Selected time-series plots of the CS coefficients for the 2009 and
2011 data sets under Model 1 }
\par\end{centering}
\begin{centering}
\includegraphics[width=12cm]{Graphs/CompareBeta1_cs_only} 
\par\end{centering}
Solid curves are the posterior means and the dotted curves are the
90\% uncertainty bands. 
\end{figure}

\begin{doublespace}
\begin{figure}
\begin{centering}
\caption{Selected time-series plots of the CS coefficients for the 2009 and
2011 data sets under Model 1}
\par\end{centering}
\begin{centering}
\includegraphics[width=12cm]{Graphs/CompareBeta2_cs_only} 
\par\end{centering}
Solid curves are the posterior means and the dotted curves are the
90\% uncertainty bands. 
\end{figure}

\begin{table}[H]
\caption{The comparison of CS coefficients from Model 1 and the static multiple
linear regression model}

\medskip{}

\centering{}%
\begin{tabular}{c|rrrrrr}
2009  & AXP  & BAC  & DIS  & GE  & JPM  & MSFT\tabularnewline
\hline 
Bayesian Posterior Means  & -0.044  & -0.776  & 0.612  & -0.035  & 0.155  & 0.071\tabularnewline
5th Percentiles of Posterior Distributions  & -0.971  & -1.568  & -0.064  & -0.913  & -1.370  & -0.546\tabularnewline
95th Percentiles of Posterior Distributions  & 0.789  & 0.066  & 1.400  & 0.734  & 1.375  & 0.675\tabularnewline
CS Coefficients from Static Regression  & -0.248  & -0.939  & 0.190  & 0.274  & -0.127  & 0.103\tabularnewline
2011  &  &  &  &  &  & \tabularnewline
\hline 
Bayesian Posterior Means  & 0.392  & -0.086  & -0.031  & 0.141  & 0.642  & 0.031\tabularnewline
5th Percentiles of Posterior Distributions  & -0.531  & -0.703  & -0.816  & -0.343  & -0.265  & -0.759\tabularnewline
95th Percentiles of Posterior Distributions  & 1.354  & 0.559  & 0.691  & 0.612  & 1.567  & 0.812\tabularnewline
CS Coefficients from Static Regression  & -0.178  & 0.533  & 0.085  & 0.057  & -0.134  & 0.401\tabularnewline
\hline 
\end{tabular}
\end{table}

\end{doublespace}

\subsubsection{The posterior distributions of the correlations of the system residual
matrix $\Omega$ using the model with CS and MR}

\begin{doublespace}
We now consider the cross-correlation between stock returns. Recall
that $\Omega$ is the cross-sectional correlation matrix between the
contemporaneous returns of different stocks. The elements in this
matrix range from roughly -0.8 to 0.6 in both data sets. In 2009,
the largest negative correlation is -0.74 (between PFE and JPM) and
the largest positive correlation is 0.53 (between JPM and AXP). In
2011, the minimum correlation is -0.65 (between AA and JPM) and the
maximum correlation is 0.56 (between AA and INTC). In both data sets,
about 10\% of the correlations are greater than 0.3 in absolute value.
Explicitly modeling these correlations is clearly important. For instance,
the large negative correlation between PFE and JPM suggests an inverse
relationship in the way in which their respective returns evolve.
These then influence the corresponding CS time-varying coefficients
through the DLM's systems equations. The upshot of this dynamic relationship
is that future forecasts of PFE and JPM stocks will be influenced
by these correlations. Importantly, the correlations themselves are
not static, since they are draws from the posterior distribution of
$\Omega$. 
\end{doublespace}

\subsection{Prediction Phase}

\begin{doublespace}
The Bayesian approach allows us to test for out-of-sample validation
since it produces the predictive distributions, not just a point prediction,
at each time period for each of the stocks in the data sets. To this
end, we use the first 126 observations in 2009 and 251 observations
in 2011 in the estimation phase, and predict one-day ahead for the
six stocks described in the estimation phase above. We can then compare
our predictions with the actual observed data for that day. Note our
modeling approach can easily provide predictions $k$ steps ahead
for any $k$; here, for illustration, we set $k=1$. 
\end{doublespace}

\subsubsection{Inferences from Tables 5 and 6}
\begin{center}
\begin{table}[H]
\begin{centering}
\caption{Summary of the predictive densities, OLS estimates and realized returns
for six selected stocks: 2009 data using Model 1\textemdash{} only
dynamic CS factors and Market Returns}
\par\end{centering}
\medskip{}

\centering{}%
\begin{tabular}{cccccc}
Stock  & Realized Return  & OLS Estimate  & DLM-SUR Mean  & SD  & Kurtosis \tabularnewline
\hline 
AXP  & -0.69  & 0.877  & 0.67  & 3.89  & 3.66 \tabularnewline
BAC  & -0.07  & -0.222  & -0.43  & 2.19  & 4.48 \tabularnewline
DIS  & -0.10  & 0.018  & -0.15  & 2.28  & 4.58 \tabularnewline
GE  & -1.43  & 0.069  & -0.16  & 1.74  & 3.86 \tabularnewline
JPM  & 0.34  & 0.162  & -0.02  & 6.21  & 4.04 \tabularnewline
MSFT  & -1.55  & 0.202  & 0.06  & 1.62  & 5.14 \tabularnewline
\hline 
\end{tabular}
\end{table}
\par\end{center}

\begin{center}
\begin{table}[H]
\begin{centering}
\caption{Summary of the predictive densities, OLS estimates and realized returns
for six selected stocks: 2011 data using Model 1\textemdash{} only
dynamic CS factors and Market Returns}
\par\end{centering}
\medskip{}

\centering{}%
\begin{tabular}{cccccc}
Stock  & Realized Return  & OLS Estimate  & DLM-SUR Mean & St. Dev.  & Kurtosis \tabularnewline
\hline 
AXP  & 0.88  & 0.062  & 0.05  & 2.03  & 3.87 \tabularnewline
BAC  & 2.90  & -0.49  & -0.31  & 0.84  & 4.04 \tabularnewline
DIS  & 0.97  & 0.202  & -0.04  & 1.54  & 4.36 \tabularnewline
GE  & 0.50  & 0.043  & 0.87  & 0.77  & 3.43 \tabularnewline
JPM  & 3.22  & 0.052  & -0.89  & 2.29  & 3.65 \tabularnewline
MSFT  & -0.14  & -0.144  & 0.00  & 0.99  & 3.71 \tabularnewline
\hline 
\end{tabular}
\end{table}
\par\end{center}

\begin{doublespace}
For the 2009 and 2011 data sets, the actual realized returns for all
the stocks are within two standard errors from the means of the respective
predictive densities. Our SUR-DLM approach not only models the covariance
between stocks (as discussed in section 4.2.2) but note that the predictive
densities feature higher levels of kurtosis than the normal distribution
for some of the predictive distributions of stock returns. In other
words, the predictive distributions for many of these returns could
be heavy-tailed. The Bayesian SUR-DLM captures such features appropriately.
The primary benefit of higher order moments is they influence the
estimates of the lower order ones. For example, if the true underlying
density is, say unimodal and leptokurtic, the probability mass at
the peak will be significantly influenced by the model used to describe
the data. Here, we have shown that the parameters are time-varying
which suggests that all the moments of the evolving probability densities
will change and influence the future moments. The kurtosis for many
of the predictive distributions clearly show that the data are leptokurtic.
Treating this explicitly (like we do) leads to better predictions.

A striking feature from Tables 5 and 6 is that the standard deviations
of the predictive densities for all the stocks are substantially smaller
in 2011 when compared to 2009. But this is not surprising. Earlier
from figures 1 and 2 we saw that the plots of the time-varying CS
coefficients are far more stable in 2011 when compared to 2009, which
was a crisis phase in the economy. Since the predictive distributions
are a function of these coefficients, their standard deviations are
appropriately influenced by the estimates of these coefficients.

Another interesting feature is that the realized returns for the six
stocks fluctuate considerably in the two data sets, implying that
the Bayesian predictive time-varying approach is better suited to
model the stock returns, rather than a fixed, static approach.

For comparison, we also include the predicted values from a standard
OLS procedure for the six stocks. It is important to emphasize how
misguided decisions could be if one merely focused on the Mean values,
be it OLS or from our model. For one, the kurtosis of the predictive
densities are much larger than that of a normal distribution. In other
words, it would be important to account for the volatility and higher
order moments of the data distribution. Point estimates, like the
mean, are largely data centric. Even here, this is evident when one
compares the 2009 versus 2011 estimates for the exact same six stocks.
What our research shows is that it is better to have a methodology
that will consistently capture \emph{all} the key moments of the predictive
density, regardless of the particular data set with which one may
be confronted. Since no model is ``perfect'', the best one could
hope for is to try and account for as many sources of variability
as possible. Our SUR-DLM model for social media sentiments is a step
in that direction. 
\end{doublespace}

\subsubsection{Inferences from Tables 7 and 8}

\begin{doublespace}
Recall from earlier (Table 3) that there are three models we are evaluating.
Model 1: This includes the dynamic CS regressor and static Market
Return factor. Model 2: This is the SUR model with static Fama-French
and momentum factors. Model 3: This is the DLM-SUR model with CS,
Fama-French and momentum factors.

To further analyze the differences between the above models, we calculate
both the Mean Absolute Errors (MAE) and the Mean Square Errors (MSE)
between the actual realized returns and the mean of predictive returns
for 15 consecutive days for the three models using both datasets.
Furthermore, we pool the 2009 and 2011 results to see if the inferences
hold using a larger dataset. A paired two-sample t-test was performed
leading to the following conclusions. Consider Table 7 and Table 8.

First, for the 2009 data, Model 1 and Model 3 outperforms Model 2
significantly with two-tailed p-value less than 1\% for both MAE and
MSE metrics. That is, there is \emph{strong evidence that adding CS
improves predictions of stock returns}.

Second, there is no significant difference between Model 2 and Model
3 which implies that \emph{adding lag Fama-French/ Momentum factors
do not offer any significant benefit for predicting stock returns}.

\begin{table}
\begin{centering}
\caption{MAE and MSE Means and Standard Errors for 15 observations}
\par\end{centering}
\medskip{}

\begin{centering}
\begin{tabular*}{12cm}{@{\extracolsep{\fill}}cccc}
\textbf{MAE}  & Model 1  & Model 2  & Model 3\tabularnewline
\hline 
2009 data set  & 26.00(10.40)  & 46.06(16.32)  & 26.49(8.51)\tabularnewline
2011 data set  & 31.85(13.54)  & 44.93(28.18)  & 35.05(16.10)\tabularnewline
pooled data set  & 28.93(12.23)  & 45.50(22.63)  & 30.77(13.38)\tabularnewline
 &  &  & \tabularnewline
\textbf{MSE}  & Model 1  & Model 2  & Model 3\tabularnewline
\hline 
2009 data set  & 52.03(39.17)  & 127.41(84.59)  & 51.51(34.91)\tabularnewline
2011 data set  & 63.83(48.27)  & 134.64(158.70)  & 78.56(65.66)\tabularnewline
pooled data set  & 57.93(43.61)  & 131.03(125.01)  & 65.04(53.47)\tabularnewline
\hline 
\end{tabular*}
\par\end{centering}
\medskip{}

Note: Standard errors are in parenthesis 
\end{table}

\begin{table}
\begin{centering}
\caption{MAE and MSE predictive comparisons}
\par\end{centering}
\medskip{}

\centering{}%
\begin{tabular*}{13cm}{@{\extracolsep{\fill}}ccc|cc|cc}
\hline 
 & \multicolumn{2}{c|}{Model 1 - Model 2} & \multicolumn{2}{c|}{Model 1 - Model 3} & \multicolumn{2}{c}{Model 2 - Model 3}\tabularnewline
\hline 
\textbf{MAE}  & t stats.  & p-value  & t stats.  & p-value  & t stats.  & p-value \tabularnewline
\hline 
2009 data set  & -4.50  & 0.0004  & -0.66  & 0.5199  & 4.40  & 0.0006\tabularnewline
2011 data set  & -1.55  & 0.1441  & -2.17  & 0.0473  & 1.06  & 0.3046\tabularnewline
pooled data set  & -3.50  & 0.0015  & -2.18  & 0.0379  & 2.87  & 0.0076\tabularnewline
\hline 
 &  & \multicolumn{1}{c}{} &  & \multicolumn{1}{c}{} &  & \tabularnewline
\hline 
\textbf{MSE}  & t stats.  & p-value  & t stats.  & p-value  & t stats.  & p-value \tabularnewline
\hline 
2009 data set  & -3.20  & 0.0060  & 0.23  & 0.8195  & 3.20  & 0.0060\tabularnewline
2011 data set  & -1.62  & 0.1280  & -2.30  & 0.0370  & 1.18  & 0.2581\tabularnewline
pooled data set  & -2.99  & 0.0056  & -0.96  & 0.0592  & 2.52  & 0.0175\tabularnewline
\hline 
\end{tabular*}
\end{table}

Third, for the 2011 data, there is a statistically significant difference
between Model 1 and Model 3 with two-tailed p-value less than 5\%
under both MAE and MSE metrics. This indicates that \emph{adding the
extra lagged Fama-French/ Momentum factors worsen the predictions}.

Fourth, there is weaker evidence that suggests Model 1 outperforms
Model 2 with two-tailed p-value less than 15\% for both MAE and MSE
metrics.

Fifth, there is no statistically significant difference for the prediction
errors between Model 2 and Model 3 but note that Model 3 has \emph{meaningfully
lower} prediction errors than Model 2. This is consistent with the
2009 data wherein Model 2 had the worst performance.

Sixth, Table 8 shows that when the 2009 and 2011 data are pooled,
Model 1 outperforms Model 2 and Model 3 significantly with two-tailed
p-value lass than 5\% under the MAE metric. With the MSE metric, Model
1 outperforms Model 2 and 3 at the 1\% significance level. Thus, when
data sets with different levels of volatility are combined, Model
1 (the one with dynamic CS and static Market Return) better predicts
returns compared to models with additional static factors in them.

In conclusion, it is crucial to emphasize the upshot of Tables 7 and
8: modeling parameter uncertainty via SUR/DLMs goes a long way in
better understanding the importance of social media sentiments and
their role in predicting stock returns, rather than adding Fama-French
and momentum factors. This is because the rich structure of the SUR-DLM
approach, along with CS and MR, are enough to describe the underlying
dynamics of stock returns. Adding more factors, even if they are statistically
different from zero, do not improve prediction; this is the principle
of parsimony at work. That is, it emphasizes a key statistical point:
models that \emph{fit} the data well do not necessarily \emph{predict}
well. 
\end{doublespace}

\section{Conclusion}

\begin{doublespace}
A novel Bayesian method to assess the relationship between social
media sentiments and future stock returns was considered. Methodologically,
the model integrated two mathematical notions: Dynamic Linear Models
(DLMs) allow us to explicitly model the time-varying relationship
between social media sentiments and future stock returns; and Seemingly
Unrelated Regressions (SURs) allow us to model the stock returns as
a system of inter-related equations that explicitly factor cross-correlations
between the returns.

The empirical analysis of the stocks in the DJIA in 2009 and 2011
provides compelling evidence to support both the time-varying and
cross-correlation hypotheses. Further, the one-day ahead predictive
distributions for many of the stocks in the DJIA have tails that are
heavier than the normal distribution. This means extreme values in
the observed data play a crucial role in forecasting stock returns.
Here, we exemplified the methodology by predicting one-day ahead.
In principle, the model could be adapted for multi-steps ahead forecasting.

Another critical finding is that models with just social media sentiments
and market returns perform at least as well as models that also include
Fama-French and Momentum Factors. We argue that this is because of
the DLM-SUR modeling approach taken in this paper. Capturing system
dynamics via the DLM component and the inter-related nature of stock
returns in the DJIA via the SUR component provides new insight into
the role of social media sentiments on stock performance in financial
markets.

It is worthy to note that traditional serial correlation (or autocorrelation)
time-series regressions are special cases of DLMs. This is readily
seen if one simply removes the state equation (given in Section 2.2)
and proceeds to model the observation equation as an autoregressive
model. A main difference between the two types of models is that in
a DLM, the relationship between the independent and dependent variable
varies over time and could be negative/positive over different time
periods. Interestingly, He et al. \citep{he2016social} found that
negative sentiments on Tweets could predict a firm's future stock
prices. It is possible that even positive Twitter sentiments might
influence predictability if the corresponding regressors were allowed
to be time-varying. This may be worthy of future research. Approaches
like Fama-Macbeth only address issues related to autocorrelated dependent
variables but do not handle dynamic relationships between independent
and dependent variables.

It may be tempting to step away from a daily DLM model for each company
like we did in this paper. This is not viable for three reasons. One,
aggregating data could likely hide underlying variation in the data.
Two, aggregation will hide sudden spikes in the data which clearly
exists in the stock returns data. Three, the Bayesian estimates will
be much improved, since ``learning'' and ``updating'' day-to-day
will better capture the local fluctuations, such as spikes, in the
data. Once again, Figure 2 confirmed this very nicely. Working with
daily data increases computation time, but this is hardly a daunting
issue in this age of high-speed computing. Indeed, it is for this
reason models like DLMs could prove useful in the burgeoning field
of ``big data'' analytics.

One of the difficulties in dealing with social media sentiments is
the changing nature of the online databases and missing data. Handling
missing covariate data requires data augmentation steps in the Markov
chain Monte Carlo algorithms. In the present context, we are unsure
how one would augment missing self-declared sentiments on a given
day since they are not missing data in the usual statistical sense.
In other words, we are led to the tough question: what probability
model should one assume for such sentiments so one could augment missing
values from it within an MCMC routine? This is a difficult question
to tackle satisfactorily. It has some similarities to modeling management
skill in mutual fund performance. To our knowledge, no one has provided
a satisfactory way to tackle that problem in the financial economics
literature.

\bibliographystyle{DSS_first_submission/elsart-num-sort}
\bibliography{CS}

\end{doublespace}

\section*{}
\end{document}
